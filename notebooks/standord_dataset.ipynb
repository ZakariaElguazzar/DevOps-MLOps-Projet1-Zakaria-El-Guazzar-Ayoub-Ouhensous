{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba2b7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-4.9.9-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (2.3.1)\n",
      "Collecting array_record>=0.5.0 (from tensorflow_datasets)\n",
      "  Downloading array_record-0.8.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting dm-tree (from tensorflow_datasets)\n",
      "  Downloading dm_tree-0.1.9-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting etils>=1.9.1 (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading etils-1.13.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting immutabledict (from tensorflow_datasets)\n",
      "  Downloading immutabledict-4.2.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (2.1.3)\n",
      "Collecting promise (from tensorflow_datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (5.29.3)\n",
      "Requirement already satisfied: psutil in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: pyarrow in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (19.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (2.32.3)\n",
      "Collecting simple_parsing (from tensorflow_datasets)\n",
      "  Downloading simple_parsing-0.1.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets)\n",
      "  Downloading tensorflow_metadata-1.17.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: termcolor in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (3.1.0)\n",
      "Requirement already satisfied: toml in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow_datasets) (1.17.0)\n",
      "Collecting einops (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (2025.3.2)\n",
      "Collecting importlib_resources (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from requests>=2.19.0->tensorflow_datasets) (2025.4.26)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from dm-tree->tensorflow_datasets) (24.3.0)\n",
      "Requirement already satisfied: six in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from promise->tensorflow_datasets) (1.17.0)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from simple_parsing->tensorflow_datasets)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /home/zakaria-el-guazzar/anaconda3/lib/python3.13/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.72.0)\n",
      "Downloading tensorflow_datasets-4.9.9-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.8.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.13.0-py3-none-any.whl (170 kB)\n",
      "Downloading dm_tree-0.1.9-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading immutabledict-4.2.2-py3-none-any.whl (4.7 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading tensorflow_metadata-1.17.2-py3-none-any.whl (31 kB)\n",
      "Building wheels for collected packages: promise\n",
      "\u001b[33m  DEPRECATION: Building 'promise' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'promise'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21482 sha256=b708042c270ea596b963b52e99918d5670d48da31c207aa471fb38926a0d08cb\n",
      "  Stored in directory: /home/zakaria-el-guazzar/.cache/pip/wheels/8f/46/1c/1f4e5d73a20eb816ead5014e97cdeb3928cf314fc46c7bab61\n",
      "Successfully built promise\n",
      "Installing collected packages: promise, importlib_resources, immutabledict, etils, einops, docstring-parser, dm-tree, tensorflow-metadata, simple_parsing, array_record, tensorflow_datasets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [tensorflow_datasets]nsorflow_datasets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed array_record-0.8.3 dm-tree-0.1.9 docstring-parser-0.17.0 einops-0.8.1 etils-1.13.0 immutabledict-4.2.2 importlib_resources-6.5.2 promise-2.3 simple_parsing-0.1.7 tensorflow-metadata-1.17.2 tensorflow_datasets-4.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9073c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 18:18:42.825243: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 18:18:43.171506: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-09 18:18:50.546441: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING:absl:Variant folder /home/zakaria-el-guazzar/tensorflow_datasets/stanford_online_products/1.0.0 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/zakaria-el-guazzar/tensorflow_datasets/stanford_online_products/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2478e08f05f74fb5b9c75c461a52c891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386be82d5d0a42c58e73ce103f1344c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41d0fa9ce4b4692b5e6cb5e7a84d519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Charger le dataset SOP\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'stanford_online_products',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,    # retourne (image, label)\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "print(ds_info)  # infos sur le dataset, classes, shape des images\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
